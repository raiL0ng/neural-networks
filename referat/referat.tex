\documentclass[bachelor, och, referat]{template}

\usepackage[utf8]{inputenc}
\usepackage{graphicx}

\usepackage{pdfpages}
\usepackage{amsmath}

\usepackage[sort,compress]{cite}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{fancyvrb}
\usepackage{longtable}
\usepackage{array}
\usepackage[english,russian]{babel}
\usepackage{minted}

\usepackage{tempora}

\usepackage[justification=centering]{caption}
\usepackage[colorlinks=false, hidelinks=true]{hyperref}


\newcommand{\eqdef}{\stackrel {\rm def}{=}}


\begin{document}

\title{Нейронные иммунные сети}

\course{5}

\group{531}

\napravlenie{10.05.01 "--- Компьютерная безопасность}


\author{Токарева Никиты Сергеевича}


\satitle{доцент}
\saname{И.\,И.\, Слеповичев}


\date{2024}

\maketitle

% Включение нумерации рисунков, формул и таблиц по разделам
% (по умолчанию - нумерация сквозная)
% (допускается оба вида нумерации)
%\secNumbering


\tableofcontents

\intro
С развитием области компьютерных наук и техники общество столкнулось с 
возрастающей проблемой киберпреступности. Одним из аспектов этой проблемы 
является разработка и распространение вредоносных программ, известных как 
компьютерные вирусы. В настоящее время обеспечение защиты компьютерных 
систем от подобных вредоносных программ является приоритетным направлением 
в области обеспечения информационной безопасности. Традиционные методы, 
основанные на сигнатурном поиске для выявления компьютерных вирусов, 
эффективны в обнаружении известных угроз, но оказываются неэффективными 
при обнаружении неизвестных вредоносных программ. Время, проходящее с 
момента появления нового компьютерного вируса до его обнаружения 
специалистами антивирусной индустрии, может быть значительным, 
что позволяет современным вредоносным программам распространяться 
и причинять серьезные ущербы. Компьютерные системы с устаревшими 
антивирусными базами становятся беспомощными перед новыми угрозами. 
Эвристические анализаторы, используемые для обнаружения неизвестных 
компьютерных вирусов, на текущий момент далеки от идеальных и часто 
либо ложно классифицируют чистые, неинфицированные файлы как вредоносные 
программы, либо не распознают зловредные программы.

Данная работа представляет собой обзор нейронных иммунных сетей (НИС), в 
которых сочетаются искусственные иммунные системы (ИИС) и самоорганизующиеся 
нейронные сети Т. Кохонена. В рамках исследования рассматривается один из 
видов самоорганизующихся нейронных сетей, применяемых в нейронных иммунных 
сетях, а также изучается взаимосвязь между биологической иммунной системой 
и искусственными иммунными системами. В дополнение к этому представлены 
алгоритмы, созданные для обнаружения вирусов при использовании ИИС.

\section{Самоорганизующиеся нейронные сети Кохонена}

Самоорганизующиеся нейронные сети (self-organising neural networks)
характеризуются обучением без учителя, в результате которого происходит 
адаптация сети к решаемой задаче. Их разработал в 80-е гг. XX в.
финский ученый Т. Кохонен. Нейронные сети
Кохонена осуществляют топологическое упорядочивание входного
пространства образов, поступающих на сеть. Они широко применяются
в задачах распознавания и визуализации образов, оптимизации и
управления.

\subsection{Общая характеристика сетей Кохонена}

Данные сети осуществляют отображение $F$ входного $n$-мерного пространства 
образов в выходное $m$-мерное пространство, т. е. $F : R^n \rightarrow R^m$.
При этом обучение здесь происходит без учителя на основе образов,
поступающих на сеть. Если сеть осуществляет кластеризацию данных,
то $m$ характеризует количество кластеров, на которые разбивается входное 
пространство образов. Архитектура нейронной сети в общем случае
представляет собой двуслойную нейронную сеть с прямыми связями (рис. \ref{nn1}).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{pics/nn1.png}
    \caption{Архитектура нейронной сети Кохонена}
    \label{nn1}
\end{figure}

Первый слой выполняет чисто распределительные функции, причем 
каждый нейрон его имеет соединения со всеми нейронными элементами 
выходного слоя. Второй слой нейронных элементов является
обрабатывающим.

Нейронная сеть Кохонена использует конкурентный принцип обучения 
и функционирования. В соответствии с этим принципом при подаче 
на сеть входного образа значение только одного нейронного элемента 
выходного слоя принимается равным 1, а выходные значения остальных 
нейронов -- 0. Нейронный элемент, имеющий выходное значение 1, 
называется победителем в конкурентной борьбе. По мере поступления 
входных образов на такую сеть посредством обучения происходит 
разбиение $n$-мерного входного пространства на различные области 
решений, каждой из которых соответствует отдельный нейрон 
обрабатывающего слоя.

Таким образом, самоорганизация таких сетей происходит в результате 
топологического упорядочивания входной информации по различным
зонам, количество которых равно $m$. Такие зоны или области решений
называются кластерами. Топологическое упорядочивание информации
напоминает процессы, происходящие в головном мозге при его развитии, 
когда осуществляется формирование топологически упорядоченных
нейронных структур.

\subsection{Обучающийся векторный квантователь (LVQ)}

Нейронная сеть для векторного квантования была предложена в
1982 г. Т. Кохоненом. Векторное квантование используется для
сжатия данных и основано на идее сопоставления входного вектора с
эталоном. Пусть имеется предварительно сформированное множество 
эталонных данных, каждое из которых называется кодовым вектором. 
Совокупность кодовых векторов называется кодовой книгой. При
поступлении входного вектора происходит его сравнение с вектором из
кодовой книги. В процессе этого выбирается такой кодовый вектор,
который наилучшим образом аппроксимирует входной вектор и его
номер применяется в качестве кода. В качестве меры подобия
между входным и эталонными векторами может использоваться евклидово 
расстояние, а в качестве векторного квантователя -- нейронная
сеть Кохонена. Тогда целью обучения сети является такая настройка
весовых коэффициентов нейрона, которая минимизирует погрешность
аппроксимации между входными образами, создающими $k$-й кластер и
весовыми коэффициентами $k$-го нейрона:

\begin{equation}
    E_k = \frac{1}{2} \sum_{l = 1}^{L_k} \sum_{i = 1}^{n} (x_i^l - w_{ik})^2,
\end{equation}

где $E_k$ -- ошибка квантования для $k$-го кластера.

Общая ошибка квантования определяется как:

\begin{equation}
    E = \sum_{k = 1}^{m} E_k.
\end{equation}

Нейронную сеть для векторного квантования принято называть
обучающимся векторным квантователем (learning vector quantization).
Она представляет собой двуслойную сеть с прямыми связями, как было
показано на рисунке \ref{nn1}. В процессе поступления эталонных векторов на
сеть она обучается так, что образуются кластеры различных эталонов,
каждому из которых соответствует свой нейрон. При поступлении на
вход такой нейронной сети неизвестного образа он идентифицируется
в соответствии с мерой близости к эталонным векторам и кодируется на
выходе сети номером нейрона. Существует большое количество вариантов 
обучения векторного квантователя, однако в данной работе рассмотрены такие
варианты, которые можно использовать в нейронных иммунных сетях.


\subsubsection{Конкурентное обучение с одним победителем}

Здесь в отдельный квант времени только один нейрон может быть
победителем. Процедура обучения векторного квантователя состоит из
следующих шагов:

\begin{enumerate}
    \item Случайно инициализируются весовые коэффициенты нейронной
    сети в диапазоне [0,1].
    \item Задается начальное значение момента времени $t = 0$.
    \item Входные образы последовательно подаются на нейронную сеть
    $x^l, l = 1, L$, и для каждого образа производятся вычисления:
    \begin{enumerate}
        \item[а)] вычисляется евклидово расстояние между входным образом и ве-
        совыми векторами нейронов выходного слоя:

        \begin{equation}
            D_j = |X - W_j| =  \sqrt{(x_1 - w_{1j})^2 + (x_1 - w_{2j})^2 + \dots + (x_n - w_{nj})^2},
        \end{equation}
        где $j = \overline{1, m}$;
        \item[б)] определяется нейрон-победитель, обеспечивающий минимальное расстояние:
        \begin{equation*}
            D_k = \min_j D_j;
        \end{equation*}
        \item[в)] производится модификация весовых коэффициентов нейронного
        элемента победителя, а весовые коэффициенты остальных нейронов не
        изменяются:

        \begin{equation*}
            w_{ij}(t + 1) = w_{ij}(t) + \gamma(t)(x_i - w{ij}(t)), \text{ если } j = k, \\
        \end{equation*}
        \begin{equation*}
            w_{ij}(t + 1) = w_{ij}(t), \text{ если } j \neq k, 
        \end{equation*}
        где $i = \overline{1, n}, j = \overline{1, m}$.
    \end{enumerate}
    \item Изменяется значение времени $t = t + 1$ и процесс повторяется, 
    начиная с шага 3.
\end{enumerate}

Обучение производится до получения желаемой степени согласования 
между входными и весовыми векторами или до тех пор, пока не
перестанут изменяться весовые коэффициенты. Для остановки процесса 
обучения можно использовать следующие правила:

\begin{enumerate}
    \item[а)] чтобы весовые коэффициенты в процессе обучения перестали
    изменяться, шаг обучения $\gamma(t)$ должен уменьшаться с течением времени, 
    например, по следующему закону:

    \begin{center}
        $\gamma(t) = \gamma_0 e^{-\frac{t}{c}}$,
    \end{center}
    где $\gamma_0 = 0.1$; $c = 1000$;
    \item[б)] обычно, как показывает практика, рекомендуется выбирать 
    общее количество эпох обучения $t = (50 \div 200)$.
\end{enumerate}


Опираясь на описанные выше шаги, был написан небольшой код, который представляет собой
реализацию нейронной сети для векторного квантования с конкурентным обучением с одним победителем (LVQ).
Код программы представлен в приложении в конце данной работы.

Общая идея заключается в том, что сеть обучается на основе входных данных и их целевых значений, 
при этом происходит обновление весов нейронов так, чтобы они адаптировались к структуре данных и 
разделяли их на кластеры. В конечном итоге, сеть может использоваться для кластеризации 
новых данных.


\subsubsection{Конкурентное обучение со многими победителями}

Для того чтобы похожие кластеры отображались на соседние нейроны 
второго слоя, можно использовать конкурентное обучение со многими 
победителями. В этом случае вокруг нейрона-победителя формируются 
соседние нейроны, для которых также производится модификация
весовых коэффициентов. Для этого вводится специальная функция притяжения, 
определяющая область притяжения нейрона-победителя в конкурентной борьбе. 
Значение функции притяжения для $p$-го нейронного
элемента, не являющегося победителем в конкурентной борьбе, можно
определить в соответствии с функцией Гаусса:

\begin{center}
    $h(t, k, p) = e^{\frac{-|k - p|^2}{2\sigma^2(t)}}$,
\end{center}

где $p$ -- номер нейронного элемента, для которого определяется 
значение функции притяжения; $k$ -- номер нейронного элемента 
победителя; $\sigma(t)$ -- среднеквадратичное отклонение (радиус 
области притяжения), уменьшающееся с течением времени по следующему закону:

\begin{center}
    $\sigma(t) = \sigma_0 e^{-\frac{t}{c}}$.
\end{center}

Значения переменных в последнем выражении можно выбирать следующим образом:

\begin{center}
    $c = \frac{1000}{\log_2{\sigma_0}}$,
\end{center}
где $\sigma_0 = m / 2$.

Тогда модификация весовых коэффициентов производится для всех
нейронных элементов обрабатывающего слоя в соответствии со 
значением функции притяжения:

\begin{center}
    $w_{ip}(t + 1) = w_{ip}(t) + \gamma h(t, k, p)(x_i - w_{ip})$.
\end{center}

В дискретном варианте вводится область притяжения $G$, которая
определяет нейронные элементы, принадлежащие классу победителей.
В этом случае весовые коэффициенты изменяются для всех нейронов,
принадлежащих области $G$:

\begin{equation*}
    \delta w_{ip} = 
    \begin{cases}
        \gamma(t)(x_i - w_{ip}), \text{ если } p \in G, \\
        0, p \notin G. \\
    \end{cases}
\end{equation*}


\subsubsection{Контролируемое конкурентное обучение}

Если заранее известно соответствие эталонных векторов нейронным
элементам, то используется контролируемое конкурентное обучение (Supervised 
Competitive Learning). Для такого обучения весовые коэффициенты 
нейрона-победителя усиливаются при корректной классификации, т. е.
когда входной образ соответствует заданному номеру нейронного элемента
второго слоя и ослабляются в противном случае. Тогда

\begin{equation*}
    w_{ik}(t + 1) = w_{ik}(t) + \gamma(x_i - x_{ik}(t))
\end{equation*}

при корректной классификации, когда $X$ и $W_k$ принадлежат к одному
классу и

\begin{equation*}
    w_{ik}(t + 1) = w_{ik}(t) - \gamma(x_i - w_{ik}(t)),
\end{equation*}

если $X$ и $W_k$ принадлежат к различным классам.

Весовые коэффициенты остальных нейронов при этом не изменяются. 
После обучения нейронная сеть может осуществлять функции
векторного квантования. При этом на выходе в каждый квант времени
будет активным только один нейрон (его выход равен 1), а остальные
нейроны будут иметь нулевые выходные значения.


\section{Искусственные иммунные системы} 
\subsection{Связь биологической иммунной системы с искусственными иммунными системами}

Механизмы, использующиеся в ис­кусственных иммунных системах, позволяют обнаруживать неизвестные
компьютерные вирусы. Искусственные иммунные системы (ИИС) 
базируются на основных принципах биологической иммунной системы (БИС) \cite{ais1}.

БИС является уникальной системой, которая ежедневно борется с болез­нетворными 
бактериями и вирусами, защищая организм от инфекций.
Уникальность БИС заключается в том, что она способна обнаруживать не
только известные вирусы и бактерии, но также и неизвестные. Иммунитет
основан на способности лимфоцитов распознавать собственные клетки
организма от чужеродных клеток.

Основными элементами иммунной системы являются лимфоциты – белые клетки.
Существуют две разновидности лимфоцитов, которые образуются из стволовых клеток в
костном мозге. После синтеза лимфоциты попадают в кровяное русло. Некоторые из них
направляются к тимусу (вилочковой железе), где происходит их созревание (Т-лимфоциты). 
Другие же попадают в лимфатические узлы, и их созревание происходит
там (В-лимфоциты). Процесс созревания незрелых лимфоцитов играет большую роль в
иммунной системе и называется селекцией антител. В результате селекции уничтожаются 
нежелательные для организма лимфоциты. Зрелые лимфоциты имеют на своей поверхности 
детекторы, которые способны обнаруживать специфический антиген (вредные
бактерии, вирусы). Контакт В-клеточных рецепторов со специфическим антигеном и 
связывание определенного его количества стимулируют рост этих клеток и последующее 
многократное деление. В результате образуются многочисленные клетки двух разновидностей:
плазматические и «клетки памяти». Плазматические клетки синтезируют антитела, тем самым 
увеличивая количество клеток, способных обнаруживать вирус. Клетки памяти являются 
копиями В-клеток, однако имеют гораздо больший период жизни, что обеспечивает
защиту организма от повторного заражения вирусом. При связывании определенного
количества вируса, Т-клетки секретируют особую группу веществ, называемую лимфокинами. 
Некоторые лимфокины способны сами разрушать антиген и зараженные клетки.
Другие лимфокины способствуют делению Т-клеток, в результате чего появляется
большое количество антител, способные реагировать на обнаруженный антиген.

\subsection{Описание принципов функционирования ИИС}

Биологическая иммунная система имеет ряд мощных вычислительных возможностей, 
такие как: распознавание, разнообразие, обучение, память, распределенный поиск,
саморегуляция, децентрализация, вероятностное обнаружение.

Построенная по основным принципам биологической иммунной системы, 
искусственная иммунная система обладает всеми ее возможностями
и, на наш взгляд, является перспективной для построения современной
системы компьютерной безопасности для защиты от вредоносных про­грамм. 
ИИС состоит из следующих процессов: создание детекторов, обу­чение и отбор 
детекторов, уничтожение нежелательных детекторов, цир­куляция 
иммунных детекторов в компьютерной системе, уничтожение
детекторов по истечении времени, обнаружение вредоносной программы,
клонирование и мутация детекторов, формирование иммунной памяти. 
Взаимодействие процессов представлено на рисунке \ref{s1}. Все 
перечислен­ные процессы находятся в тесном взаимодействии. Еще одной 
отличи­тельной способностью ИИС является отсутствие единого центра 
управле­ния.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{pics/1.png}
    \caption{Взаимодействие процессов искусственной иммунной системы}
    \label{s1}
\end{figure} 

Рассмотрим подробнее каждый из перечисленных процессов.
Процесс генерации детекторов предназначен для создания иммунных
детекторов, которые являются основными элементами ИИС и выполняют
функцию обнаружения вредоносных программ. Для построения иммун­ных 
детекторов используются искусственные нейронные сети, а именно, 
LVQ сеть (обучающийся векторный квантователь). В процессе ге­нерации 
формируется определенное количество детекторов, каждый из
которых представляет отдельную нейронную сеть.

Первоначально детекторы не способны отличать чистые файлы от вре­доносных 
программ. Поэтому необходим процесс обучения иммунных
детекторов. На стадии обучения иммунные детекторы обучаются распознавать 
зловредные программы и не реагировать на чистые файлы. Обу­чение 
детекторов проходит по следующему алгоритму:

\begin{itemize}
    \item случайным образом выбирается некоторое количество чистых фай­лов 
    (например, утилиты операционной системы) и некоторое количество
    вредоносных программ;
    \item из выбранных файлов также случайным образом выбирается не­
    сколько фрагментов определенной длины (размерность фрагментов зави­сит 
    от количества входов искусственной нейронной сети, которая форми­рует 
    детектор);
    \item выбранные фрагменты образуют обучающую выборку для ИНС и
    подаются на ее вход.
\end{itemize}

Использование разнообразных файлов и вредоносных программ для
формирования обучающей выборки позволяет создавать разнообразные
иммунные детекторы, способные обнаружить вероятные вредоносные
программы.

После обучения детекторы проходят стадию отбора. Механизм отбора
необходим для предотвращения попаданию в компьютерную систему 
не­желательных детекторов. Нежелательным детектором называется такой
детектор, который реагирует на чистые файлы. Такой детектор должен
быть уничтожен.

Обученные иммунные детекторы циркулируют в компьютерной сис­теме, 
проверяя и классифицируя файлы. Каждому детектору отводится
определенное время, на протяжении которого он может находиться в
компьютерной системе. После истечения выделенного времени детектор,
который не обнаружил вредоносной программы, уничтожается, а на его
место приходит новый детектор. Механизм выделения времени для 
существования детектора и уничтожения по истечении выделенного времени
позволяет ИИС избавляться от слабых иммунных детекторов и поддержи­вает 
принцип постоянного обновления детекторов.

При обнаружении иммунным детектором вредоносной программы
происходит процесс клонирования. Клонирование подразумевает созда­ние 
большого количества однотипных детекторов (клонируется тот детек­тор, 
который обнаружил вредоносную программу). Зачастую, при попа­дании 
компьютерного вируса в систему, он заражает большое количество
файлов, путем внедрения копии своего тела в файлы-жертвы. Процесс
клонирования позволяет иммунной системе в кратчайшие сроки изба­виться 
от всех проявлений обнаруженного компьютерного вируса.

После избавления компьютерной системы от вредоносной программы
выбирается наиболее приспособленный к обнаруженному вирусу детек­тор 
и трансформируется в детектор иммунной памяти. Иммунная память
хранит информацию обо всех вирусах, которые когда-либо заражали 
ком­пьютерную систему. Детекторы иммунной памяти существуют в 
компью­терной системе достаточно долгий промежуток времени и позволяют 
опе­ративно реагировать на повторное заражение.

% \subsection{Роль ИИС в обнаружении и борьбе с угрозами}

% \section{Нейронные иммунные сети}

% \subsection{Внедрение }
% \subsection{}


% \subsection{Перспективы нейронных иммунных сетей}

\section{Алгоритм функционирования нейросетевой иммунной системы}

В данном разделе рассматриваются процессы генерации, обучения, отбора и функционирова­
ния иммунных детекторов на основе нейронных сетей. Здесь 
нейросетевой иммунный детектор (НИД) представлен в виде черного ящика, который
имеет $n$-входов и два выхода (рис. \ref{nid}).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{pics/nid.png}
    \caption{Нейросетевой иммунный детектор}
    \label{nid}
\end{figure} 

Выходные значения детектора формируются после подачи всех
образов на него в соответствии со следующим выражением:

\begin{equation}
    Z_1 =
    \begin{cases}
        1, \text{ если чистый файл} \\
        0, \text{ иначе.} \\
    \end{cases}
    Z_2 =
    \begin{cases}
        1, \text{ если вирус} \\
        0, \text{ иначе.} \\
    \end{cases}
    \label{eq1}
\end{equation}

Обучающая выборка формируется из чистых файлов (класс чистых
программ) и вредоносных программ (класс вредоносных программ). Желательно 
также иметь представителей всех типов вредоносных программ -- черви, 
троянские программы, макровирусы и т.д. При обуче­нии нейронной сети
необходимо указать, где данные из чистых файлов, а где из
вредоносных программ.

Пусть $T$ -- множество чистых файлов, a $F$ -- множество вредоносных
файлов. Из них случайным образом формируется множество входных об­
разов для обучения $i$-го детектора.

\begin{equation}
    X_i =
    \begin{bmatrix}
        X_i^1 \\
        X_i^2 \\
        \vdots \\
        X_i^L \\
    \end{bmatrix}
    =
    \begin{bmatrix}
        X_{i1}^1 & X_{i2}^1 & \dots & X_{in}^1 \\
        X_{i1}^2 & X_{i2}^2 & \dots & X_{in}^2 \\
        && \vdots & \\
        X_{i1}^L & X_{i2}^L & \dots & X_{in}^L \\    
    \end{bmatrix},
    \label{eq2}
\end{equation}

где $L$ -- размерность обучающей выборки.

Соответственно, множество эталонных образов выглядят следующим
образом:

\begin{equation}
    l_i =
    \begin{bmatrix}
        l_i^1 \\
        l_i^2 \\
        \vdots \\
        l_i^L \\
    \end{bmatrix}
    =
    \begin{bmatrix}
        l_{i1}^1 & l_{i2}^1 \\
        l_{i1}^2 & l_{i2}^2 \\
        \vdots \\
        l_{i1}^L & l_{i2}^L \\    
    \end{bmatrix},
    \label{eq3}
\end{equation}


Эталонные выходные значения для $i$-го детектора формируются сле­дующим образом:

\begin{equation}
    l_{i1}^k = 
    \begin{cases}
        1, \text{ если } X_i^k \in T \\
        0, \text{ иначе.} \\
    \end{cases}
    l_{i2}^k = 
    \begin{cases}
        1, \text{ если } X_i^k \in F \\
        0, \text{ иначе.} \\
    \end{cases}
    \label{eq4}
\end{equation}

Обучение каждого детектора осуществляется с целью минимизации
суммарной квадратичной ошибки детектора. Суммарная квадратичная
ошибка $i$-го детектора определяется следующим образом:

\begin{equation}
    E_i = \frac{1}{2}  \sum_{k = 1}^{L} \sum_{j = 1}^{2} (Z_{ij}^k - l_{ij}^k)^2,
    \label{eq5}
\end{equation}

где $Z_{ij}^k$ -- значение $j$-го выхода $i$-го детектора при подаче на вход его $k$-то
образа.

Общий алгоритм функционирования нейросетевой иммунной системы можно представить в виде следующей последовательности:

\begin{enumerate}
    \item Генерация начальной популяции иммунных детекторов, каждый из
    которых представляет собой искусственную нейронную сеть со случай­
    ными синаптическими связями:

    \begin{equation}
        D = \{D_i, i = \overline{1, r}\},
    \end{equation}

    где $D_i$ - $i$-й нейросетевой иммунный детектор, $r$ -- общее количество детекторов.
    \item Обучение сформированных иммунных нейросетевых детекторов.
    Обучающая выборка формируется случайньм образом из совокупности
    чистых файлов (как правило, это разнообразные системные утилиты опе­
    рационной системы), и из совокупности вредоносных программ, или их
    сигнатур. Эталонные выходные значения нейронной сети формируются
    согласно (\ref{eq4}).
    \item Отбор (селекция) нейросетевых иммунных детекторов на тестовой
    выборке. На данной итерации уничтожаются те детекторы, которые 
    ока­зались неспособны к обучению, и детекторы, в работе которых наблюда­ются 
    различные недостатки (например, ложные срабатывания). Для этого
    каждый детектор проверяется на тестовой выборке. В результате для каж­дого 
    детектора определяется значение квадратичной ошибки $E_i$ (\ref{eq5}).

    Селекция детектора производится следующим образом:

    \begin{equation}
        D_i = 
        \begin{cases}
            0, \text{ если } E_i \neq 0 \\
            D_i, \text{ иначе.}
        \end{cases}
        \label{eq7}
    \end{equation}

    где 0 обозначает операцию уничтожения детектора.

    \item Каждый детектор наделяется временем жизни и случайным образом
    выбирает файл для сканирования из совокупности файлов, которые он не
    проверял.
    \item Сканирование каждым детектором выбранного файла, в результате
    которого определяются выходные значения детекторов $Z_{i1} Z_{i2}, i = \overline{1, r}$.
    \item Если $i$-й детектор не обнаружил вирус в сканируемом файле, т.е.
    $Z_{i1} = 1$ и $Z_{i2} = 0$, то он выбирает следующий файл для сканирования. Если
    время жизни $i$-го детектора закончилось, то он уничтожается и вместо
    него генерируется новый детектор.
    \item Если $i$-й детектор обнаружил вирус в сканируемом файле, т.е. $Z_{i1} = 0$
    и $Z_{i2} = 1$, то подается сигнал об обнаружении вредоносного файла и осуществляются 
    операции клонирования и мутации соответствующего детектора. 
    Операция мутации заключается в дополнительном обучении детекто­ров-клонов 
    на обнаруженном вредоносном файле. В результате создается
    совокупность детекторов, настроенных на обнаруженную вредоносную
    программу
    
    \begin{equation*}
        D_i = (D_{i1}, D_{i2}, \dots, D_{in}).
    \end{equation*}

    \item Отбор клонированных детекторов, которые являются наиболее при­
    способленными к обнаружению вредоносной программы. Если $E_{ij} < E_i$, то
    детектор прошел отбор. Здесь $E_{ij}$ -- суммарная квадратичная ошибка $j$-го
    клона $i$-го детектора, которая вычисляется на вредоносном файле.
    \item Детекторы-клоны осуществляют сканирование файлового про­странства 
    компьютерной системы до тех пор, пока не произойдет уничто­жение 
    всех проявлений вредоносной программы.
    \item Формирование детекторов иммунной памяти. На этой итерации
    определяются нейросетевые иммунные детекторы, показавшие наилучшие 
    результаты при обнаружении присутствующего в компьютерной системе вируса. 
    Детекторы иммунной памяти находятся в системе достаточ­но 
    длительное время и обеспечивают защиту от повторного заражения.
\end{enumerate}
    
Особенностью предложенного алгоритма является то, что каждый
нейросетевой иммунный детектор является полностью самостоятельным
объектом. Он случайным образом выбирает файл из списка для его проверки. 
После проверки одного файла детектор переходит к следующему
случайно выбранному файлу. При этом соблюдается принцип децентрализации 
системы безопасности, построенной на основе комбинации мето­дов 
нейронных сетей и искусственных иммунных систем, что значительно
повышает отказоустойчивость и защищенность системы в целом.

\conclusion

Перспективы нейронных иммунных сетей в ближайшем будущем представляют 
собой захватывающий направленный прогресс в области кибербезопасности и 
искусственного интеллекта.

Нейронные иммунные сети, объединяя искусственные иммунные системы и нейронные сети, 
могут стать более эффективными в обнаружении неизвестных вирусов 
и вредоносных программ. Использование нейросетей для анализа поведения 
системы может улучшить способность выявлять новые угрозы, которые 
не имеют сигнатур в существующих базах данных.

Исследования в области НИС могут привести к созданию инновационных методов 
обнаружения, основанных на комбинации биологических принципов иммунной системы 
и высокоточных алгоритмов машинного обучения.

Таким образом, в ближайшем будущем нейронные иммунные сети могут играть 
важную роль в повышении уровня кибербезопасности, предоставляя более 
эффективные и адаптивные средства защиты от постоянно эволюционирующих 
киберугроз.




\begin{thebibliography}{15}
    \bibitem{nn1}
    Головко, В. А. Нейросетевые технологии обработки данных : учеб. пособие / В. А. Головко, В. В. Краснопрошин // Минск : БГУ,
    2017. - 263 с.
    \bibitem{nn2}
    Головко, B. A. Нейронные сети: обучение, организация, применение // Нейрокомпью­теры и их применение : учеб, пособие. - M., 2001. - 256 с.
    \bibitem{ais3}
    Безобразов, С. В. Искусственные иммунные системы для защиты информации: при­менение LVQ сети // Нейроинформатика-2007: 
    материалы IX Всеросс. науч.-техн. конф., Москва, МИФИ, 2007. С. 27-35.
    \bibitem{ais4}
    Безобразов, С. В. Искусственные иммунные системы для защиты информации: обнаружение и классификация компьютерных вирусов /
    С. В. Безобразов, В. А. Головко // Нейроинформатика-2008: материалы IX Всеросс. науч.-техн. конф., Москва, МИФИ, 2008. С. 23-27.
    \bibitem{ais1}
    Безобразов, С. В. Искусственные иммунные системы для защиты информации: обнаружение и классификация компьютерных вирусов //
    Брест : БГТУ, 2008. - 10 с.
    \bibitem{ais2}
    Безобразов, С. В. Искусственные иммунные системы: принципы построения [Электронный ресурс] : описание принципа построения
    искусственных имммунных систем. - URL: https://rep.bstu.by/bitstream/handle/data/1179/3-5.pdf?sequence=1 (дата обращения 11.01.2024). -
    Загл. с экрана. - Яз. рус.
    \bibitem{ais5}
    Кушнир, Н. В. Искусственные иммунные системы: обзор и современное состояние [Электронный ресурс] / Н. В. Кушнир, А. В. Кушнир,
    Е. В. Анацкая, П. А. Катышева, К. Г. Устинов // Научные труды КубГТУ [Электронный ресурс] : [сайт]. - URL: https://ntk.kubstu.ru/data/mc/0019/0714.pdf 
    (дата обращения 12.01.2024). - Загл. с экрана. - Яз. рус


\end{thebibliography}

\appendix

    \section{Код программы lvq\_realisation.py}
    \inputminted[fontsize=\small]{python3}{code/lvq_realisation.py}

    \section{Код программы main.py}
    \inputminted[fontsize=\small]{python3}{code/main.py}
    
    \section{Файл train\_parameters.json, содержащий параметры необходимые для обучения нейронной сети}
    \inputminted[fontsize=\small]{JSON}{code/train_parameters.json}
    
    \section{Файл new\_parameters.json, содержащий новые данные для кластеризации.}
    \inputminted[fontsize=\small]{JSON}{code/new_parameters.json}


\end{document}